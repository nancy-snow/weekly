## 周报概要20220703
> 这段时间在准备考试之外，主要看的是两篇利用预训练模型来改进GAN的discriminator的文献，在不同的数据集上，这两篇分别是目前的SOTA模型，根据FID指标衡量评测标准，FID大概在2左右（DALLE 2目前的FID在7-9左右）。

---

### 1. CVPR 2022 Ensembling Off-the-shelf Models for GAN Training
* 在大规模数据集的加持下，很多预训练模型（包括监督学习和自监督学习）在特征提取方面表现得十分出色，也就是说它们已经在此基础上学到了一些知识，结合预训练模型进行下游任务的处理表现得更加出色。本文首次让GAN的训练能加持上预训练模型（这里主要是对discriminator加载目前的SOTA预训练模型）来提高D的性能，从而G的能力也会随之增强（从大规模表征学习中转移知识，即使用预训练的深度特征提取器来帮助生成模型的训练）。
* 完整的阅读笔记可以点击[此处](https://docs.qq.com/doc/p/61f7a8c8ba82d2384eabfa441ebde154a95e15bf?dver=3.0.0)查看。

---

### 2. NeurIPS 2021 Projected Gans Converge Faster
* GAN生成高质量图片的代价是很难训练，它们需要仔细的正则化、大量的计算和昂贵的超参数扫描。本文的突出贡献是将生成的样本和真实样本投影到固定的、预先训练的特征空间。由于发现鉴别器不能充分利用预训练模型中更深层的特征，本文提出了一种更有效的策略，即跨通道（Cross-Channel Mixing）和跨分辨率（Cross-Scale Mixing）混合特征。效果：提高了图像质量、采样效率和收敛速度。与之前最低的FID相比，Projected GAN的速度最高可快40倍（相同配置下从5天降到3小时）。
* 完整的阅读笔记可以点击[此处](https://docs.qq.com/doc/p/f48b9c2b6f39957d7ae4f2de724edc244eb16d38?dver=3.0.0)查看。

